{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Deep learning libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, optimizers, callbacks\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.applications import VGG16, ResNet50\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Computer vision and image processing\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "\n",
    "# Machine learning utilities\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Check GPU availability\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU Available: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92f932c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Dataset configuration\n",
    "DATASET_PATH = '/path/to/chest_xray'  # Update this path\n",
    "TRAIN_DIR = os.path.join(DATASET_PATH, 'train')\n",
    "VAL_DIR = os.path.join(DATASET_PATH, 'val')\n",
    "TEST_DIR = os.path.join(DATASET_PATH, 'test')\n",
    "\n",
    "# Model parameters\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# Class names\n",
    "CLASS_NAMES = ['NORMAL', 'PNEUMONIA']\n",
    "NUM_CLASSES = len(CLASS_NAMES)\n",
    "\n",
    "# Create results directory\n",
    "RESULTS_DIR = 'results'\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "os.makedirs(os.path.join(RESULTS_DIR, 'models'), exist_ok=True)\n",
    "os.makedirs(os.path.join(RESULTS_DIR, 'plots'), exist_ok=True)\n",
    "\n",
    "print(f\"Train directory: {TRAIN_DIR}\")\n",
    "print(f\"Validation directory: {VAL_DIR}\")\n",
    "print(f\"Test directory: {TEST_DIR}\")\n",
    "print(f\"Image size: {IMG_SIZE}\")\n",
    "print(f\"Classes: {CLASS_NAMES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f548e2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def explore_dataset(data_dir, split_name):\n",
    "    \"\"\"Explore dataset structure and class distribution\"\"\"\n",
    "    print(f\"\\n=== {split_name.upper()} SET ANALYSIS ===\")\n",
    "    \n",
    "    class_counts = {}\n",
    "    total_images = 0\n",
    "    \n",
    "    for class_name in CLASS_NAMES:\n",
    "        class_path = os.path.join(data_dir, class_name)\n",
    "        if os.path.exists(class_path):\n",
    "            count = len(os.listdir(class_path))\n",
    "            class_counts[class_name] = count\n",
    "            total_images += count\n",
    "            print(f\"{class_name}: {count} images\")\n",
    "    \n",
    "    print(f\"Total images: {total_images}\")\n",
    "    \n",
    "    # Calculate class distribution\n",
    "    if total_images > 0:\n",
    "        for class_name, count in class_counts.items():\n",
    "            percentage = (count / total_images) * 100\n",
    "            print(f\"{class_name}: {percentage:.1f}%\")\n",
    "    \n",
    "    return class_counts\n",
    "\n",
    "# Explore all splits\n",
    "train_counts = explore_dataset(TRAIN_DIR, 'train')\n",
    "val_counts = explore_dataset(VAL_DIR, 'validation')\n",
    "test_counts = explore_dataset(TEST_DIR, 'test')\n",
    "\n",
    "# Visualize class distribution\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "splits = ['Train', 'Validation', 'Test']\n",
    "counts = [train_counts, val_counts, test_counts]\n",
    "\n",
    "for i, (split, count_dict) in enumerate(zip(splits, counts)):\n",
    "    if count_dict:\n",
    "        classes = list(count_dict.keys())\n",
    "        values = list(count_dict.values())\n",
    "        \n",
    "        bars = axes[i].bar(classes, values, color=['skyblue', 'lightcoral'])\n",
    "        axes[i].set_title(f'{split} Set Distribution')\n",
    "        axes[i].set_ylabel('Number of Images')\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for bar, value in zip(bars, values):\n",
    "            axes[i].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1,\n",
    "                        str(value), ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(RESULTS_DIR, 'plots', 'class_distribution.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac32063",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def display_sample_images(data_dir, class_names, samples_per_class=3):\n",
    "    \"\"\"Display sample images from each class\"\"\"\n",
    "    fig, axes = plt.subplots(len(class_names), samples_per_class, \n",
    "                            figsize=(15, len(class_names) * 4))\n",
    "    \n",
    "    if len(class_names) == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    for i, class_name in enumerate(class_names):\n",
    "        class_path = os.path.join(data_dir, class_name)\n",
    "        if os.path.exists(class_path):\n",
    "            image_files = os.listdir(class_path)[:samples_per_class]\n",
    "            \n",
    "            for j, img_file in enumerate(image_files):\n",
    "                img_path = os.path.join(class_path, img_file)\n",
    "                img = load_img(img_path, target_size=IMG_SIZE)\n",
    "                \n",
    "                axes[i, j].imshow(img)\n",
    "                axes[i, j].set_title(f'{class_name}\\n{img_file}')\n",
    "                axes[i, j].axis('off')\n",
    "    \n",
    "    plt.suptitle('Sample Images from Dataset', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(RESULTS_DIR, 'plots', 'sample_images.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Display sample images\n",
    "display_sample_images(TRAIN_DIR, CLASS_NAMES, samples_per_class=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee479cc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def analyze_image_statistics(data_dir, class_names, num_samples=100):\n",
    "    \"\"\"Analyze image statistics like dimensions, brightness, etc.\"\"\"\n",
    "    stats = {\n",
    "        'widths': [],\n",
    "        'heights': [],\n",
    "        'mean_intensities': [],\n",
    "        'std_intensities': [],\n",
    "        'classes': []\n",
    "    }\n",
    "    \n",
    "    for class_name in class_names:\n",
    "        class_path = os.path.join(data_dir, class_name)\n",
    "        if os.path.exists(class_path):\n",
    "            image_files = os.listdir(class_path)[:num_samples]\n",
    "            \n",
    "            for img_file in image_files:\n",
    "                img_path = os.path.join(class_path, img_file)\n",
    "                try:\n",
    "                    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "                    if img is not None:\n",
    "                        stats['widths'].append(img.shape[1])\n",
    "                        stats['heights'].append(img.shape[0])\n",
    "                        stats['mean_intensities'].append(np.mean(img))\n",
    "                        stats['std_intensities'].append(np.std(img))\n",
    "                        stats['classes'].append(class_name)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {img_path}: {e}\")\n",
    "    \n",
    "    return pd.DataFrame(stats)\n",
    "\n",
    "# Analyze image statistics\n",
    "stats_df = analyze_image_statistics(TRAIN_DIR, CLASS_NAMES, num_samples=200)\n",
    "\n",
    "# Visualize statistics\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Image dimensions\n",
    "axes[0, 0].hist(stats_df['widths'], bins=30, alpha=0.7, label='Width')\n",
    "axes[0, 0].hist(stats_df['heights'], bins=30, alpha=0.7, label='Height')\n",
    "axes[0, 0].set_title('Image Dimensions Distribution')\n",
    "axes[0, 0].set_xlabel('Pixels')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# Mean intensity by class\n",
    "sns.boxplot(data=stats_df, x='classes', y='mean_intensities', ax=axes[0, 1])\n",
    "axes[0, 1].set_title('Mean Intensity Distribution by Class')\n",
    "axes[0, 1].set_ylabel('Mean Pixel Intensity')\n",
    "\n",
    "# Standard deviation by class\n",
    "sns.boxplot(data=stats_df, x='classes', y='std_intensities', ax=axes[1, 0])\n",
    "axes[1, 0].set_title('Pixel Intensity Std Distribution by Class')\n",
    "axes[1, 0].set_ylabel('Std of Pixel Intensity')\n",
    "\n",
    "# Intensity scatter plot\n",
    "for class_name in CLASS_NAMES:\n",
    "    class_data = stats_df[stats_df['classes'] == class_name]\n",
    "    axes[1, 1].scatter(class_data['mean_intensities'], class_data['std_intensities'], \n",
    "                      alpha=0.6, label=class_name)\n",
    "axes[1, 1].set_title('Mean vs Std Intensity')\n",
    "axes[1, 1].set_xlabel('Mean Intensity')\n",
    "axes[1, 1].set_ylabel('Std Intensity')\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(RESULTS_DIR, 'plots', 'image_statistics.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"\\nImage Statistics Summary:\")\n",
    "print(stats_df.groupby('classes').agg({\n",
    "    'widths': ['mean', 'std', 'min', 'max'],\n",
    "    'heights': ['mean', 'std', 'min', 'max'],\n",
    "    'mean_intensities': ['mean', 'std'],\n",
    "    'std_intensities': ['mean', 'std']\n",
    "}).round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a40222c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def create_baseline_generators():\n",
    "    \"\"\"Create data generators with minimal augmentation (baseline)\"\"\"\n",
    "    \n",
    "    # Baseline: Only rescaling and minimal augmentation\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=5,\n",
    "        width_shift_range=0.05,\n",
    "        height_shift_range=0.05,\n",
    "        horizontal_flip=True,\n",
    "        validation_split=0.2  # Use 20% for validation if no separate val set\n",
    "    )\n",
    "    \n",
    "    # Validation and test: only rescaling\n",
    "    val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    \n",
    "    # Create generators\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        TRAIN_DIR,\n",
    "        target_size=IMG_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='binary',  # Binary classification\n",
    "        subset='training',\n",
    "        seed=42,\n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    # Use validation split from training data if val_dir doesn't exist\n",
    "    if os.path.exists(VAL_DIR) and len(os.listdir(VAL_DIR)) > 0:\n",
    "        validation_generator = val_test_datagen.flow_from_directory(\n",
    "            VAL_DIR,\n",
    "            target_size=IMG_SIZE,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            class_mode='binary',\n",
    "            shuffle=False\n",
    "        )\n",
    "    else:\n",
    "        validation_generator = train_datagen.flow_from_directory(\n",
    "            TRAIN_DIR,\n",
    "            target_size=IMG_SIZE,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            class_mode='binary',\n",
    "            subset='validation',\n",
    "            seed=42,\n",
    "            shuffle=False\n",
    "        )\n",
    "    \n",
    "    test_generator = val_test_datagen.flow_from_directory(\n",
    "        TEST_DIR,\n",
    "        target_size=IMG_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='binary',\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    return train_generator, validation_generator, test_generator\n",
    "\n",
    "# Create baseline generators\n",
    "train_gen_baseline, val_gen_baseline, test_gen_baseline = create_baseline_generators()\n",
    "\n",
    "print(f\"Training samples: {train_gen_baseline.samples}\")\n",
    "print(f\"Validation samples: {val_gen_baseline.samples}\")\n",
    "print(f\"Test samples: {test_gen_baseline.samples}\")\n",
    "print(f\"Class indices: {train_gen_baseline.class_indices}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78865878",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def create_strong_augmentation_generators():\n",
    "    \"\"\"Create data generators with strong augmentation\"\"\"\n",
    "    \n",
    "    # Strong augmentation for training\n",
    "    train_datagen_strong = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.15,\n",
    "        zoom_range=0.15,\n",
    "        horizontal_flip=True,\n",
    "        brightness_range=[0.8, 1.2],\n",
    "        channel_shift_range=20,\n",
    "        fill_mode='nearest',\n",
    "        validation_split=0.2\n",
    "    )\n",
    "    \n",
    "    # Validation and test: only rescaling\n",
    "    val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    \n",
    "    # Create generators\n",
    "    train_generator = train_datagen_strong.flow_from_directory(\n",
    "        TRAIN_DIR,\n",
    "        target_size=IMG_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='binary',\n",
    "        subset='training',\n",
    "        seed=42,\n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    # Use validation split from training data if val_dir doesn't exist\n",
    "    if os.path.exists(VAL_DIR) and len(os.listdir(VAL_DIR)) > 0:\n",
    "        validation_generator = val_test_datagen.flow_from_directory(\n",
    "            VAL_DIR,\n",
    "            target_size=IMG_SIZE,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            class_mode='binary',\n",
    "            shuffle=False\n",
    "        )\n",
    "    else:\n",
    "        validation_generator = train_datagen_strong.flow_from_directory(\n",
    "            TRAIN_DIR,\n",
    "            target_size=IMG_SIZE,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            class_mode='binary',\n",
    "            subset='validation',\n",
    "            seed=42,\n",
    "            shuffle=False\n",
    "        )\n",
    "    \n",
    "    test_generator = val_test_datagen.flow_from_directory(\n",
    "        TEST_DIR,\n",
    "        target_size=IMG_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='binary',\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    return train_generator, validation_generator, test_generator\n",
    "\n",
    "# Create strong augmentation generators\n",
    "train_gen_strong, val_gen_strong, test_gen_strong = create_strong_augmentation_generators()\n",
    "\n",
    "print(f\"Strong augmentation - Training samples: {train_gen_strong.samples}\")\n",
    "print(f\"Strong augmentation - Validation samples: {val_gen_strong.samples}\")\n",
    "print(f\"Strong augmentation - Test samples: {test_gen_strong.samples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea9810c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def visualize_augmentations(generator, num_samples=8):\n",
    "    \"\"\"Visualize the effect of data augmentation\"\"\"\n",
    "    \n",
    "    # Get a batch of augmented images\n",
    "    batch_x, batch_y = next(generator)\n",
    "    \n",
    "    # Create subplot\n",
    "    fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for i in range(min(num_samples, len(batch_x))):\n",
    "        img = batch_x[i]\n",
    "        label = \"PNEUMONIA\" if batch_y[i] > 0.5 else \"NORMAL\"\n",
    "        \n",
    "        axes[i].imshow(img)\n",
    "        axes[i].set_title(f'{label}')\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.suptitle('Augmented Training Images', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# Visualize baseline augmentation\n",
    "print(\"Baseline Augmentation Examples:\")\n",
    "fig1 = visualize_augmentations(train_gen_baseline)\n",
    "plt.savefig(os.path.join(RESULTS_DIR, 'plots', 'baseline_augmentation.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Visualize strong augmentation\n",
    "print(\"\\nStrong Augmentation Examples:\")\n",
    "fig2 = visualize_augmentations(train_gen_strong)\n",
    "plt.savefig(os.path.join(RESULTS_DIR, 'plots', 'strong_augmentation.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6becfa6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def create_custom_cnn(input_shape=(224, 224, 3), num_classes=1):\n",
    "    \"\"\"\n",
    "    Create a custom CNN architecture for chest X-ray classification\n",
    "    \"\"\"\n",
    "    model = models.Sequential([\n",
    "        # First Convolutional Block\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "        \n",
    "        # Second Convolutional Block\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "        \n",
    "        # Third Convolutional Block\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "        \n",
    "        # Fourth Convolutional Block\n",
    "        layers.Conv2D(256, (3, 3), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(256, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "        \n",
    "        # Fifth Convolutional Block\n",
    "        layers.Conv2D(512, (3, 3), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "        \n",
    "        # Flatten and Dense Layers\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.5),\n",
    "        \n",
    "        # Output layer (sigmoid for binary classification)\n",
    "        layers.Dense(num_classes, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create model instance\n",
    "model_architecture = create_custom_cnn(input_shape=(*IMG_SIZE, 3), num_classes=1)\n",
    "\n",
    "# Display model summary\n",
    "model_architecture.summary()\n",
    "\n",
    "# Visualize model architecture\n",
    "tf.keras.utils.plot_model(\n",
    "    model_architecture, \n",
    "    to_file=os.path.join(RESULTS_DIR, 'plots', 'model_architecture.png'),\n",
    "    show_shapes=True,\n",
    "    show_layer_names=True,\n",
    "    rankdir='TB',\n",
    "    dpi=200\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ff5eee",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def get_callbacks(model_name):\n",
    "    \"\"\"Create callbacks for training\"\"\"\n",
    "    \n",
    "    callbacks_list = [\n",
    "        # Save best model\n",
    "        callbacks.ModelCheckpoint(\n",
    "            filepath=os.path.join(RESULTS_DIR, 'models', f'{model_name}_best.h5'),\n",
    "            monitor='val_accuracy',\n",
    "            save_best_only=True,\n",
    "            save_weights_only=False,\n",
    "            verbose=1\n",
    "        ),\n",
    "        \n",
    "        # Reduce learning rate on plateau\n",
    "        callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=5,\n",
    "            min_lr=1e-7,\n",
    "            verbose=1\n",
    "        ),\n",
    "        \n",
    "        # Early stopping\n",
    "        callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=10,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        \n",
    "        # CSV Logger\n",
    "        callbacks.CSVLogger(\n",
    "            os.path.join(RESULTS_DIR, f'{model_name}_training_log.csv')\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    return callbacks_list\n",
    "\n",
    "# Compile model function\n",
    "def compile_model(model, learning_rate=LEARNING_RATE):\n",
    "    \"\"\"Compile the model with appropriate optimizer and metrics\"\"\"\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', 'precision', 'recall']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Calculate class weights to handle imbalance\n",
    "def calculate_class_weights(generator):\n",
    "    \"\"\"Calculate class weights for imbalanced dataset\"\"\"\n",
    "    from sklearn.utils.class_weight import compute_class_weight\n",
    "    \n",
    "    # Get all labels\n",
    "    labels = generator.classes\n",
    "    \n",
    "    # Calculate class weights\n",
    "    class_weights = compute_class_weight(\n",
    "        'balanced',\n",
    "        classes=np.unique(labels),\n",
    "        y=labels\n",
    "    )\n",
    "    \n",
    "    class_weight_dict = dict(enumerate(class_weights))\n",
    "    print(f\"Class weights: {class_weight_dict}\")\n",
    "    \n",
    "    return class_weight_dict\n",
    "\n",
    "# Calculate class weights for baseline training\n",
    "class_weights = calculate_class_weights(train_gen_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc0deda",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Create and compile baseline model\n",
    "model_baseline = create_custom_cnn(input_shape=(*IMG_SIZE, 3), num_classes=1)\n",
    "model_baseline = compile_model(model_baseline)\n",
    "\n",
    "# Get callbacks for baseline model\n",
    "baseline_callbacks = get_callbacks('baseline_model')\n",
    "\n",
    "# Train baseline model\n",
    "print(\"Training Baseline Model (Minimal Augmentation)...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "history_baseline = model_baseline.fit(\n",
    "    train_gen_baseline,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_gen_baseline,\n",
    "    callbacks=baseline_callbacks,\n",
    "    class_weight=class_weights,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Save training history\n",
    "np.save(os.path.join(RESULTS_DIR, 'baseline_history.npy'), history_baseline.history)\n",
    "print(\"Baseline model training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c680f2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def plot_training_history(history, model_name, save_path=None):\n",
    "    \"\"\"Plot training history metrics\"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # Plot accuracy\n",
    "    axes[0, 0].plot(history['accuracy'], label='Training Accuracy')\n",
    "    axes[0, 0].plot(history['val_accuracy'], label='Validation Accuracy')\n",
    "    axes[0, 0].set_title(f'{model_name} - Accuracy')\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Accuracy')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True)\n",
    "    \n",
    "    # Plot loss\n",
    "    axes[0, 1].plot(history['loss'], label='Training Loss')\n",
    "    axes[0, 1].plot(history['val_loss'], label='Validation Loss')\n",
    "    axes[0, 1].set_title(f'{model_name} - Loss')\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('Loss')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True)\n",
    "    \n",
    "    # Plot precision\n",
    "    axes[1, 0].plot(history['precision'], label='Training Precision')\n",
    "    axes[1, 0].plot(history['val_precision'], label='Validation Precision')\n",
    "    axes[1, 0].set_title(f'{model_name} - Precision')\n",
    "    axes[1, 0].set_xlabel('Epoch')\n",
    "    axes[1, 0].set_ylabel('Precision')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True)\n",
    "    \n",
    "    # Plot recall\n",
    "    axes[1, 1].plot(history['recall'], label='Training Recall')\n",
    "    axes[1, 1].plot(history['val_recall'], label='Validation Recall')\n",
    "    axes[1, 1].set_title(f'{model_name} - Recall')\n",
    "    axes[1, 1].set_xlabel('Epoch')\n",
    "    axes[1, 1].set_ylabel('Recall')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Plot baseline model training history\n",
    "print(\"Baseline Model Training History:\")\n",
    "plot_training_history(\n",
    "    history_baseline.history, \n",
    "    'Baseline Model (Minimal Augmentation)',\n",
    "    os.path.join(RESULTS_DIR, 'plots', 'baseline_training_history.png')\n",
    ")\n",
    "\n",
    "# Plot strong augmentation model training history\n",
    "print(\"\\nStrong Augmentation Model Training History:\")\n",
    "plot_training_history(\n",
    "    history_strong.history, \n",
    "    'Strong Augmentation Model',\n",
    "    os.path.join(RESULTS_DIR, 'plots', 'strong_augmentation_training_history.png')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a58ff58",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_generator, model_name):\n",
    "    \"\"\"Comprehensive model evaluation\"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"EVALUATING {model_name.upper()}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # Reset generator\n",
    "    test_generator.reset()\n",
    "    \n",
    "    # Get predictions\n",
    "    predictions = model.predict(test_generator, verbose=1)\n",
    "    predicted_classes = (predictions > 0.5).astype(int).flatten()\n",
    "    true_classes = test_generator.classes\n",
    "    \n",
    "    # Calculate metrics\n",
    "    test_loss, test_accuracy, test_precision, test_recall = model.evaluate(\n",
    "        test_generator, verbose=0\n",
    "    )\n",
    "    \n",
    "    # Calculate F1 score\n",
    "    f1 = 2 * (test_precision * test_recall) / (test_precision + test_recall)\n",
    "    \n",
    "    print(f\"\\nTest Metrics:\")\n",
    "    print(f\"Accuracy: {test_accuracy:.4f}\")\n",
    "    print(f\"Precision: {test_precision:.4f}\")\n",
    "    print(f\"Recall: {test_recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"Loss: {test_loss:.4f}\")\n",
    "    \n",
    "    # Classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(\n",
    "        true_classes, predicted_classes, \n",
    "        target_names=CLASS_NAMES\n",
    "    ))\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(true_classes, predicted_classes)\n",
    "    \n",
    "    # Calculate additional metrics from confusion matrix\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    sensitivity = tp / (tp + fn)  # Recall/True Positive Rate\n",
    "    specificity = tn / (tn + fp)  # True Negative Rate\n",
    "    \n",
    "    print(f\"\\nAdditional Metrics:\")\n",
    "    print(f\"Sensitivity (True Positive Rate): {sensitivity:.4f}\")\n",
    "    print(f\"Specificity (True Negative Rate): {specificity:.4f}\")\n",
    "    print(f\"False Positive Rate: {fp/(fp+tn):.4f}\")\n",
    "    print(f\"False Negative Rate: {fn/(fn+tp):.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'predictions': predictions,\n",
    "        'predicted_classes': predicted_classes,\n",
    "        'true_classes': true_classes,\n",
    "        'accuracy': test_accuracy,\n",
    "        'precision': test_precision,\n",
    "        'recall': test_recall,\n",
    "        'f1': f1,\n",
    "        'loss': test_loss,\n",
    "        'confusion_matrix': cm,\n",
    "        'sensitivity': sensitivity,\n",
    "        'specificity': specificity\n",
    "    }\n",
    "\n",
    "def plot_confusion_matrix(cm, class_names, model_name, save_path=None):\n",
    "    \"\"\"Plot confusion matrix\"\"\"\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title(f'Confusion Matrix - {model_name}')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def plot_roc_curve(true_classes, predictions, model_name, save_path=None):\n",
    "    \"\"\"Plot ROC curve\"\"\"\n",
    "    \n",
    "    fpr, tpr, _ = roc_curve(true_classes, predictions)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, \n",
    "             label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'ROC Curve - {model_name}')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True)\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    return roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66ecf05",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Load best baseline model\n",
    "model_baseline_best = tf.keras.models.load_model(\n",
    "    os.path.join(RESULTS_DIR, 'models', 'baseline_model_best.h5')\n",
    ")\n",
    "\n",
    "# Evaluate baseline model\n",
    "baseline_results = evaluate_model(model_baseline_best, test_gen_baseline, 'Baseline Model')\n",
    "\n",
    "# Plot confusion matrix for baseline\n",
    "plot_confusion_matrix(\n",
    "    baseline_results['confusion_matrix'], \n",
    "    CLASS_NAMES,\n",
    "    'Baseline Model',\n",
    "    os.path.join(RESULTS_DIR, 'plots', 'baseline_confusion_matrix.png')\n",
    ")\n",
    "\n",
    "# Plot ROC curve for baseline\n",
    "baseline_auc = plot_roc_curve(\n",
    "    baseline_results['true_classes'],\n",
    "    baseline_results['predictions'],\n",
    "    'Baseline Model',\n",
    "    os.path.join(RESULTS_DIR, 'plots', 'baseline_roc_curve.png')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0375ee3d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Load best strong augmentation model\n",
    "model_strong_best = tf.keras.models.load_model(\n",
    "    os.path.join(RESULTS_DIR, 'models', 'strong_augmentation_model_best.h5')\n",
    ")\n",
    "\n",
    "# Evaluate strong augmentation model\n",
    "strong_results = evaluate_model(model_strong_best, test_gen_strong, 'Strong Augmentation Model')\n",
    "\n",
    "# Plot confusion matrix for strong augmentation\n",
    "plot_confusion_matrix(\n",
    "    strong_results['confusion_matrix'], \n",
    "    CLASS_NAMES,\n",
    "    'Strong Augmentation Model',\n",
    "    os.path.join(RESULTS_DIR, 'plots', 'strong_augmentation_confusion_matrix.png')\n",
    ")\n",
    "\n",
    "# Plot ROC curve for strong augmentation\n",
    "strong_auc = plot_roc_curve(\n",
    "    strong_results['true_classes'],\n",
    "    strong_results['predictions'],\n",
    "    'Strong Augmentation Model',\n",
    "    os.path.join(RESULTS_DIR, 'plots', 'strong_augmentation_roc_curve.png')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83e59a2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def create_comparison_table(baseline_results, strong_results, baseline_auc, strong_auc):\n",
    "    \"\"\"Create a comparison table of both models\"\"\"\n",
    "    \n",
    "    comparison_data = {\n",
    "        'Metric': [\n",
    "            'Accuracy', 'Precision', 'Recall', 'F1 Score', \n",
    "            'Sensitivity', 'Specificity', 'AUC', 'Loss'\n",
    "        ],\n",
    "        'Baseline Model': [\n",
    "            f\"{baseline_results['accuracy']:.4f}\",\n",
    "            f\"{baseline_results['precision']:.4f}\",\n",
    "            f\"{baseline_results['recall']:.4f}\",\n",
    "            f\"{baseline_results['f1']:.4f}\",\n",
    "            f\"{baseline_results['sensitivity']:.4f}\",\n",
    "            f\"{baseline_results['specificity']:.4f}\",\n",
    "            f\"{baseline_auc:.4f}\",\n",
    "            f\"{baseline_results['loss']:.4f}\"\n",
    "        ],\n",
    "        'Strong Augmentation Model': [\n",
    "            f\"{strong_results['accuracy']:.4f}\",\n",
    "            f\"{strong_results['precision']:.4f}\",\n",
    "            f\"{strong_results['recall']:.4f}\",\n",
    "            f\"{strong_results['f1']:.4f}\",\n",
    "            f\"{strong_results['sensitivity']:.4f}\",\n",
    "            f\"{strong_results['specificity']:.4f}\",\n",
    "            f\"{strong_auc:.4f}\",\n",
    "            f\"{strong_results['loss']:.4f}\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    df_comparison = pd.DataFrame(comparison_data)\n",
    "    return df_comparison\n",
    "\n",
    "# Create comparison table\n",
    "comparison_df = create_comparison_table(baseline_results, strong_results, baseline_auc, strong_auc)\n",
    "print(\"MODEL COMPARISON RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Save comparison to CSV\n",
    "comparison_df.to_csv(os.path.join(RESULTS_DIR, 'model_comparison.csv'), index=False)\n",
    "\n",
    "# Visualize comparison\n",
    "metrics_to_plot = ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'AUC']\n",
    "baseline_values = [\n",
    "    baseline_results['accuracy'], baseline_results['precision'], \n",
    "    baseline_results['recall'], baseline_results['f1'], baseline_auc\n",
    "]\n",
    "strong_values = [\n",
    "    strong_results['accuracy'], strong_results['precision'], \n",
    "    strong_results['recall'], strong_results['f1'], strong_auc\n",
    "]\n",
    "\n",
    "x = np.arange(len(metrics_to_plot))\n",
    "width = 0.35\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "bars1 = ax.bar(x - width/2, baseline_values, width, label='Baseline Model', alpha=0.8)\n",
    "bars2 = ax.bar(x + width/2, strong_values, width, label='Strong Augmentation Model', alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('Metrics')\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_title('Model Performance Comparison')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(metrics_to_plot)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "def add_value_labels(bars):\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.annotate(f'{height:.3f}',\n",
    "                   xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                   xytext=(0, 3),  # 3 points vertical offset\n",
    "                   textcoords=\"offset points\",\n",
    "                   ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "add_value_labels(bars1)\n",
    "add_value_labels(bars2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(RESULTS_DIR, 'plots', 'model_comparison.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8381048e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def plot_learning_curves_comparison():\n",
    "    \"\"\"Plot learning curves for both models side by side\"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # Accuracy comparison\n",
    "    axes[0, 0].plot(history_baseline.history['val_accuracy'], label='Baseline', linewidth=2)\n",
    "    axes[0, 0].plot(history_strong.history['val_accuracy'], label='Strong Aug', linewidth=2)\n",
    "    axes[0, 0].set_title('Validation Accuracy Comparison')\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Accuracy')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Loss comparison\n",
    "    axes[0, 1].plot(history_baseline.history['val_loss'], label='Baseline', linewidth=2)\n",
    "    axes[0, 1].plot(history_strong.history['val_loss'], label='Strong Aug', linewidth=2)\n",
    "    axes[0, 1].set_title('Validation Loss Comparison')\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('Loss')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Training vs Validation Accuracy - Baseline\n",
    "    axes[1, 0].plot(history_baseline.history['accuracy'], label='Train', linewidth=2)\n",
    "    axes[1, 0].plot(history_baseline.history['val_accuracy'], label='Val', linewidth=2)\n",
    "    axes[1, 0].set_title('Baseline Model - Train vs Val Accuracy')\n",
    "    axes[1, 0].set_xlabel('Epoch')\n",
    "    axes[1, 0].set_ylabel('Accuracy')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Training vs Validation Accuracy - Strong Augmentation\n",
    "    axes[1, 1].plot(history_strong.history['accuracy'], label='Train', linewidth=2)\n",
    "    axes[1, 1].plot(history_strong.history['val_accuracy'], label='Val', linewidth=2)\n",
    "    axes[1, 1].set_title('Strong Aug Model - Train vs Val Accuracy')\n",
    "    axes[1, 1].set_xlabel('Epoch')\n",
    "    axes[1, 1].set_ylabel('Accuracy')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(RESULTS_DIR, 'plots', 'learning_curves_comparison.png'), \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "plot_learning_curves_comparison()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f786ff37",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def analyze_predictions(model, test_generator, model_name, num_examples=12):\n",
    "    \"\"\"Analyze model predictions with example images\"\"\"\n",
    "    \n",
    "    # Reset generator\n",
    "    test_generator.reset()\n",
    "    \n",
    "    # Get predictions for the entire test set\n",
    "    predictions = model.predict(test_generator, verbose=1)\n",
    "    predicted_classes = (predictions > 0.5).astype(int).flatten()\n",
    "    true_classes = test_generator.classes\n",
    "    \n",
    "    # Get filenames\n",
    "    filenames = test_generator.filenames\n",
    "    \n",
    "    # Find correct and incorrect predictions\n",
    "    correct_mask = predicted_classes == true_classes\n",
    "    incorrect_mask = ~correct_mask\n",
    "    \n",
    "    # Get confidence scores\n",
    "    confidence_scores = np.where(predicted_classes == 1, predictions.flatten(), 1 - predictions.flatten())\n",
    "    \n",
    "    print(f\"\\n{model_name} - Prediction Analysis:\")\n",
    "    print(f\"Total predictions: {len(predictions)}\")\n",
    "    print(f\"Correct predictions: {np.sum(correct_mask)}\")\n",
    "    print(f\"Incorrect predictions: {np.sum(incorrect_mask)}\")\n",
    "    print(f\"Accuracy: {np.sum(correct_mask) / len(predictions):.4f}\")\n",
    "    \n",
    "    # Plot examples of correct and incorrect predictions\n",
    "    fig, axes = plt.subplots(3, 4, figsize=(16, 12))\n",
    "    \n",
    "    # Get some correct predictions\n",
    "    correct_indices = np.where(correct_mask)[0]\n",
    "    if len(correct_indices) >= 6:\n",
    "        selected_correct = np.random.choice(correct_indices, 6, replace=False)\n",
    "    else:\n",
    "        selected_correct = correct_indices\n",
    "    \n",
    "    # Get some incorrect predictions\n",
    "    incorrect_indices = np.where(incorrect_mask)[0]\n",
    "    if len(incorrect_indices) >= 6:\n",
    "        selected_incorrect = np.random.choice(incorrect_indices, 6, replace=False)\n",
    "    else:\n",
    "        selected_incorrect = incorrect_indices\n",
    "    \n",
    "    # Plot correct predictions\n",
    "    for i, idx in enumerate(selected_correct):\n",
    "        if i < 6:\n",
    "            row = i // 2\n",
    "            col = i % 2\n",
    "            \n",
    "            # Load and display image\n",
    "            img_path = os.path.join(test_generator.directory, filenames[idx])\n",
    "            img = load_img(img_path, target_size=IMG_SIZE)\n",
    "            \n",
    "            axes[row, col].imshow(img)\n",
    "            \n",
    "            true_label = CLASS_NAMES[true_classes[idx]]\n",
    "            pred_label = CLASS_NAMES[predicted_classes[idx]]\n",
    "            confidence = confidence_scores[idx]\n",
    "            \n",
    "            axes[row, col].set_title(f'✓ True: {true_label}\\nPred: {pred_label}\\nConf: {confidence:.3f}')\n",
    "            axes[row, col].axis('off')\n",
    "    \n",
    "    # Plot incorrect predictions\n",
    "    for i, idx in enumerate(selected_incorrect):\n",
    "        if i < 6:\n",
    "            row = i // 2\n",
    "            col = i % 2 + 2\n",
    "            \n",
    "            # Load and display image\n",
    "            img_path = os.path.join(test_generator.directory, filenames[idx])\n",
    "            img = load_img(img_path, target_size=IMG_SIZE)\n",
    "            \n",
    "            axes[row, col].imshow(img)\n",
    "            \n",
    "            true_label = CLASS_NAMES[true_classes[idx]]\n",
    "            pred_label = CLASS_NAMES[predicted_classes[idx]]\n",
    "            confidence = confidence_scores[idx]\n",
    "            \n",
    "            axes[row, col].set_title(f'✗ True: {true_label}\\nPred: {pred_label}\\nConf: {confidence:.3f}')\n",
    "            axes[row, col].axis('off')\n",
    "    \n",
    "    # Add column headers\n",
    "    axes[0, 0].text(-0.1, 1.1, 'CORRECT PREDICTIONS', transform=axes[0, 0].transAxes, \n",
    "                   fontsize=14, fontweight='bold', ha='center')\n",
    "    axes[0, 2].text(0.1, 1.1, 'INCORRECT PREDICTIONS', transform=axes[0, 2].transAxes, \n",
    "                   fontsize=14, fontweight='bold', ha='center')\n",
    "    \n",
    "    plt.suptitle(f'{model_name} - Prediction Examples', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(RESULTS_DIR, 'plots', f'{model_name.lower().replace(\" \", \"_\")}_predictions.png'), \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    return {\n",
    "        'correct_indices': correct_indices,\n",
    "        'incorrect_indices': incorrect_indices,\n",
    "        'confidence_scores': confidence_scores,\n",
    "        'filenames': filenames\n",
    "    }\n",
    "\n",
    "# Analyze baseline model predictions\n",
    "baseline_analysis = analyze_predictions(model_baseline_best, test_gen_baseline, 'Baseline Model')\n",
    "\n",
    "# Analyze strong augmentation model predictions  \n",
    "strong_analysis = analyze_predictions(model_strong_best, test_gen_strong, 'Strong Augmentation Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854a808a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def visualize_feature_maps(model, test_generator, layer_names=None, num_images=2):\n",
    "    \"\"\"Visualize feature maps from intermediate layers\"\"\"\n",
    "    \n",
    "    if layer_names is None:\n",
    "        # Get some convolutional layer names\n",
    "        layer_names = [layer.name for layer in model.layers \n",
    "                      if 'conv2d' in layer.name][:6]  # First 6 conv layers\n",
    "    \n",
    "    # Create a model that outputs feature maps\n",
    "    feature_map_model = tf.keras.Model(\n",
    "        inputs=model.input,\n",
    "        outputs=[model.get_layer(name).output for name in layer_names]\n",
    "    )\n",
    "    \n",
    "    # Get some test images\n",
    "    test_generator.reset()\n",
    "    batch_x, batch_y = next(test_generator)\n",
    "    \n",
    "    for img_idx in range(min(num_images, len(batch_x))):\n",
    "        img = batch_x[img_idx:img_idx+1]  # Keep batch dimension\n",
    "        feature_maps = feature_map_model.predict(img)\n",
    "        \n",
    "        # Create subplots\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "        axes = axes.ravel()\n",
    "        \n",
    "        for i, (layer_name, feature_map) in enumerate(zip(layer_names, feature_maps)):\n",
    "            if i < 6:  # Only plot first 6 layers\n",
    "                # Take the first few feature maps from the layer\n",
    "                feature_map_to_plot = feature_map[0, :, :, 0]  # First channel\n",
    "                \n",
    "                axes[i].imshow(feature_map_to_plot, cmap='viridis')\n",
    "                axes[i].set_title(f'{layer_name}\\nShape: {feature_map.shape[1:]}')\n",
    "                axes[i].axis('off')\n",
    "        \n",
    "        plt.suptitle(f'Feature Maps - Image {img_idx + 1}')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(RESULTS_DIR, 'plots', f'feature_maps_img_{img_idx + 1}.png'), \n",
    "                    dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "\n",
    "# Visualize feature maps for baseline model\n",
    "print(\"Feature Maps - Baseline Model:\")\n",
    "visualize_feature_maps(model_baseline_best, test_gen_baseline, num_images=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5672734f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
    "    \"\"\"Generate Grad-CAM heatmap\"\"\"\n",
    "    \n",
    "    # Create a model that maps the input image to the activations\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "    \n",
    "    # Compute the gradient of the predicted class for our input image\n",
    "    with tf.GradientTape() as tape:\n",
    "        last_conv_layer_output, preds = grad_model(img_array)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(preds[0])\n",
    "        class_channel = preds[:, pred_index]\n",
    "    \n",
    "    # Gradient of the output with respect to the output feature map\n",
    "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
    "    \n",
    "    # Mean intensity of the gradient over specific feature map channel\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "    \n",
    "    # Multiply each channel by \"how important this channel is\"\n",
    "    last_conv_layer_output = last_conv_layer_output[0]\n",
    "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "    \n",
    "    # Normalize the heatmap\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "    return heatmap.numpy()\n",
    "\n",
    "def display_gradcam(model, test_generator, model_name, num_examples=6):\n",
    "    \"\"\"Display Grad-CAM visualizations\"\"\"\n",
    "    \n",
    "    # Find the last convolutional layer\n",
    "    last_conv_layer = None\n",
    "    for layer in reversed(model.layers):\n",
    "        if 'conv2d' in layer.name:\n",
    "            last_conv_layer = layer.name\n",
    "            break\n",
    "    \n",
    "    if last_conv_layer is None:\n",
    "        print(\"No convolutional layer found!\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Using last conv layer: {last_conv_layer}\")\n",
    "    \n",
    "    # Get some test images\n",
    "    test_generator.reset()\n",
    "    batch_x, batch_y = next(test_generator)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for i in range(min(num_examples, len(batch_x))):\n",
    "        img = batch_x[i:i+1]  # Keep batch dimension\n",
    "        \n",
    "        # Get prediction\n",
    "        prediction = model.predict(img, verbose=0)\n",
    "        predicted_class = int(prediction[0] > 0.5)\n",
    "        confidence = prediction[0][0] if predicted_class == 1 else 1 - prediction[0][0]\n",
    "        \n",
    "        # Generate heatmap\n",
    "        heatmap = make_gradcam_heatmap(img, model, last_conv_layer)\n",
    "        \n",
    "        # Display original image\n",
    "        original_img = batch_x[i]\n",
    "        \n",
    "        # Resize heatmap to match original image\n",
    "        heatmap_resized = cv2.resize(heatmap, (IMG_SIZE[1], IMG_SIZE[0]))\n",
    "        \n",
    "        # Create superimposed image\n",
    "        heatmap_colored = plt.cm.jet(heatmap_resized)[:, :, :3]\n",
    "        superimposed = heatmap_colored * 0.4 + original_img * 0.6\n",
    "        \n",
    "        axes[i].imshow(superimposed)\n",
    "        axes[i].set_title(f'Pred: {CLASS_NAMES[predicted_class]}\\nConf: {confidence:.3f}')\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.suptitle(f'Grad-CAM Visualizations - {model_name}')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(RESULTS_DIR, 'plots', f'{model_name.lower().replace(\" \", \"_\")}_gradcam.png'), \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Generate Grad-CAM for both models\n",
    "print(\"Grad-CAM Visualizations:\")\n",
    "display_gradcam(model_baseline_best, test_gen_baseline, 'Baseline Model')\n",
    "display_gradcam(model_strong_best, test_gen_strong, 'Strong Augmentation Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc160ecd",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def analyze_model_complexity():\n",
    "    \"\"\"Analyze and compare model complexity\"\"\"\n",
    "    \n",
    "    # Get model parameters\n",
    "    baseline_params = model_baseline_best.count_params()\n",
    "    strong_params = model_strong_best.count_params()\n",
    "    \n",
    "    # Calculate model size (approximate)\n",
    "    baseline_size_mb = baseline_params * 4 / (1024 * 1024)  # Assuming float32\n",
    "    strong_size_mb = strong_params * 4 / (1024 * 1024)\n",
    "    \n",
    "    print(\"MODEL COMPLEXITY ANALYSIS\")\n",
    "    print(\"=\" * 40)\n",
    "    print(f\"Baseline Model:\")\n",
    "    print(f\"  - Total Parameters: {baseline_params:,}\")\n",
    "    print(f\"  - Model Size: {baseline_size_mb:.2f} MB\")\n",
    "    print(f\"\\nStrong Augmentation Model:\")\n",
    "    print(f\"  - Total Parameters: {strong_params:,}\")\n",
    "    print(f\"  - Model Size: {strong_size_mb:.2f} MB\")\n",
    "    \n",
    "    return {\n",
    "        'baseline_params': baseline_params,\n",
    "        'strong_params': strong_params,\n",
    "        'baseline_size_mb': baseline_size_mb,\n",
    "        'strong_size_mb': strong_size_mb\n",
    "    }\n",
    "\n",
    "def calculate_inference_time(model, test_generator, model_name, num_batches=10):\n",
    "    \"\"\"Calculate average inference time\"\"\"\n",
    "    \n",
    "    import time\n",
    "    \n",
    "    test_generator.reset()\n",
    "    times = []\n",
    "    \n",
    "    for i in range(num_batches):\n",
    "        batch_x, _ = next(test_generator)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        _ = model.predict(batch_x, verbose=0)\n",
    "        end_time = time.time()\n",
    "        \n",
    "        times.append(end_time - start_time)\n",
    "        \n",
    "        if i >= test_generator.samples // test_generator.batch_size:\n",
    "            break\n",
    "    \n",
    "    avg_time = np.mean(times)\n",
    "    avg_time_per_image = avg_time / test_generator.batch_size\n",
    "    \n",
    "    print(f\"\\n{model_name} - Inference Time:\")\n",
    "    print(f\"  - Average batch time: {avg_time:.4f} seconds\")\n",
    "    print(f\"  - Average per image: {avg_time_per_image:.4f} seconds\")\n",
    "    print(f\"  - Images per second: {1/avg_time_per_image:.2f}\")\n",
    "    \n",
    "    return avg_time_per_image\n",
    "\n",
    "# Analyze model complexity\n",
    "complexity_stats = analyze_model_complexity()\n",
    "\n",
    "# Calculate inference times\n",
    "baseline_inference_time = calculate_inference_time(model_baseline_best, test_gen_baseline, 'Baseline Model')\n",
    "strong_inference_time = calculate_inference_time(model_strong_best, test_gen_strong, 'Strong Augmentation Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cbb2f8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def generate_final_report():\n",
    "    \"\"\"Generate a comprehensive final report\"\"\"\n",
    "    \n",
    "    report = f\"\"\"\n",
    "# CHEST X-RAY PNEUMONIA CLASSIFICATION - FINAL REPORT\n",
    "{'='*60}\n",
    "\n",
    "## EXPERIMENT OVERVIEW\n",
    "This study compared a custom CNN architecture with two different data augmentation strategies:\n",
    "1. **Baseline Model**: Minimal augmentation (rotation, shifts, horizontal flip)\n",
    "2. **Strong Augmentation Model**: Extensive augmentation (rotation, shifts, shear, zoom, brightness, etc.)\n",
    "\n",
    "## DATASET INFORMATION\n",
    "- **Source**: Kaggle Chest X-Ray Images (Pneumonia) by Paul Timothy Mooney\n",
    "- **Total Images**: 5,863 X-ray images (JPEG format)\n",
    "- **Classes**: NORMAL vs PNEUMONIA (binary classification)\n",
    "- **Split**: Train/Validation/Test folders with class subfolders\n",
    "- **Image Size**: {IMG_SIZE[0]}x{IMG_SIZE[1]} pixels\n",
    "- **Class Distribution**: Imbalanced dataset (more pneumonia cases)\n",
    "\n",
    "## MODEL ARCHITECTURE\n",
    "- **Type**: Custom Convolutional Neural Network\n",
    "- **Layers**: 5 Convolutional blocks + Dense layers\n",
    "- **Parameters**: {complexity_stats['baseline_params']:,}\n",
    "- **Features**: Batch normalization, dropout, global average pooling\n",
    "- **Activation**: ReLU (hidden), Sigmoid (output)\n",
    "- **Optimizer**: Adam with learning rate {LEARNING_RATE}\n",
    "\n",
    "## TRAINING CONFIGURATION\n",
    "- **Epochs**: {EPOCHS}\n",
    "- **Batch Size**: {BATCH_SIZE}\n",
    "- **Loss Function**: Binary crossentropy\n",
    "- **Class Weights**: Applied to handle class imbalance\n",
    "- **Callbacks**: ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "- **Metrics**: Accuracy, Precision, Recall\n",
    "\n",
    "## RESULTS SUMMARY\n",
    "\n",
    "### Baseline Model (Minimal Augmentation)\n",
    "- **Test Accuracy**: {baseline_results['accuracy']:.4f}\n",
    "- **Test Precision**: {baseline_results['precision']:.4f}\n",
    "- **Test Recall**: {baseline_results['recall']:.4f}\n",
    "- **Test F1 Score**: {baseline_results['f1']:.4f}\n",
    "- **AUC**: {baseline_auc:.4f}\n",
    "- **Sensitivity**: {baseline_results['sensitivity']:.4f}\n",
    "- **Specificity**: {baseline_results['specificity']:.4f}\n",
    "\n",
    "### Strong Augmentation Model\n",
    "- **Test Accuracy**: {strong_results['accuracy']:.4f}\n",
    "- **Test Precision**: {strong_results['precision']:.4f}\n",
    "- **Test Recall**: {strong_results['recall']:.4f}\n",
    "- **Test F1 Score**: {strong_results['f1']:.4f}\n",
    "- **AUC**: {strong_auc:.4f}\n",
    "- **Sensitivity**: {strong_results['sensitivity']:.4f}\n",
    "- **Specificity**: {strong_results['specificity']:.4f}\n",
    "\n",
    "## PERFORMANCE COMPARISON\n",
    "\"\"\"\n",
    "    \n",
    "    # Determine which model performed better\n",
    "    if strong_results['accuracy'] > baseline_results['accuracy']:\n",
    "        better_model = \"Strong Augmentation Model\"\n",
    "        accuracy_improvement = strong_results['accuracy'] - baseline_results['accuracy']\n",
    "        report += f\"✅ **Winner**: {better_model}\\n\"\n",
    "        report += f\"📈 **Accuracy Improvement**: +{accuracy_improvement:.4f} ({accuracy_improvement*100:.2f}%)\\n\"\n",
    "    else:\n",
    "        better_model = \"Baseline Model\"\n",
    "        accuracy_difference = baseline_results['accuracy'] - strong_results['accuracy']\n",
    "        report += f\"✅ **Winner**: {better_model}\\n\"\n",
    "        report += f\"📉 **Accuracy Difference**: +{accuracy_difference:.4f} ({accuracy_difference*100:.2f}%)\\n\"\n",
    "    \n",
    "    report += f\"\"\"\n",
    "## KEY FINDINGS\n",
    "\n",
    "### Data Augmentation Impact\n",
    "\"\"\"\n",
    "    \n",
    "    if strong_results['accuracy'] > baseline_results['accuracy']:\n",
    "        report += \"- Strong data augmentation **improved** model performance\\n\"\n",
    "        report += \"- Enhanced generalization and reduced overfitting\\n\"\n",
    "        report += \"- Better handling of dataset variability\\n\"\n",
    "    else:\n",
    "        report += \"- Strong data augmentation **did not improve** model performance\\n\"\n",
    "        report += \"- Possible over-augmentation or dataset-specific characteristics\\n\"\n",
    "        report += \"- Baseline augmentation was sufficient for this dataset\\n\"\n",
    "    \n",
    "    report += f\"\"\"\n",
    "### Medical Relevance\n",
    "- **Sensitivity (True Positive Rate)**: Critical for medical diagnosis\n",
    "  - Baseline: {baseline_results['sensitivity']:.4f}\n",
    "  - Strong Aug: {strong_results['sensitivity']:.4f}\n",
    "- **Specificity (True Negative Rate)**: Important to avoid false alarms\n",
    "  - Baseline: {baseline_results['specificity']:.4f}\n",
    "  - Strong Aug: {strong_results['specificity']:.4f}\n",
    "\n",
    "### Model Efficiency\n",
    "- **Inference Time**: {baseline_inference_time:.4f} seconds per image\n",
    "- **Model Size**: {complexity_stats['baseline_size_mb']:.2f} MB\n",
    "- **Suitable for**: Real-time clinical applications\n",
    "\n",
    "## RECOMMENDATIONS\n",
    "\n",
    "### For Clinical Deployment\n",
    "1. **Model Selection**: Use {better_model.lower()} for production\n",
    "2. **Threshold Tuning**: Consider adjusting prediction threshold based on clinical needs\n",
    "3. **Validation**: Perform extensive validation on diverse datasets\n",
    "4. **Integration**: Ensure proper integration with hospital PACS systems\n",
    "\n",
    "### For Future Research\n",
    "1. **Architecture**: Experiment with transfer learning (ResNet, DenseNet)\n",
    "2. **Data**: Collect more diverse and balanced datasets\n",
    "3. **Preprocessing**: Investigate lung segmentation and enhancement techniques\n",
    "4. **Ensemble**: Combine multiple models for improved performance\n",
    "\n",
    "## LIMITATIONS\n",
    "- Limited to single dataset source\n",
    "- Binary classification only (Normal vs Pneumonia)\n",
    "- No distinction between bacterial and viral pneumonia\n",
    "- Pediatric focus (1-5 years old patients)\n",
    "\n",
    "## CONCLUSION\n",
    "This study demonstrates the {'positive' if strong_results['accuracy'] > baseline_results['accuracy'] else 'limited'} impact of strong data augmentation on chest X-ray pneumonia classification. The custom CNN architecture achieved {'good' if max(baseline_results['accuracy'], strong_results['accuracy']) > 0.85 else 'moderate'} performance with potential for clinical applications after further validation and optimization.\n",
    "\n",
    "## FILES GENERATED\n",
    "- Model weights: `results/models/`\n",
    "- Training logs: `results/*.csv`\n",
    "- Visualizations: `results/plots/`\n",
    "- Comparison table: `results/model_comparison.csv`\n",
    "- This report: `results/final_report.txt`\n",
    "\n",
    "{'='*60}\n",
    "Report generated on: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "\"\"\"\n",
    "    \n",
    "    # Save report to file\n",
    "    with open(os.path.join(RESULTS_DIR, 'final_report.txt'), 'w') as f:\n",
    "        f.write(report)\n",
    "    \n",
    "    print(report)\n",
    "\n",
    "# Generate final report\n",
    "generate_final_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd22f72",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_for_deployment(best_model, model_name):\n",
    "    \"\"\"Prepare model for deployment\"\"\"\n",
    "    \n",
    "    # Save in different formats\n",
    "    deployment_dir = os.path.join(RESULTS_DIR, 'deployment')\n",
    "    os.makedirs(deployment_dir, exist_ok=True)\n",
    "    \n",
    "    # Save as HDF5\n",
    "    model_path_h5 = os.path.join(deployment_dir, f'{model_name}_final.h5')\n",
    "    best_model.save(model_path_h5)\n",
    "    print(f\"Model saved as HDF5: {model_path_h5}\")\n",
    "    \n",
    "    # Save as SavedModel format (for TensorFlow Serving)\n",
    "    model_path_saved = os.path.join(deployment_dir, f'{model_name}_savedmodel')\n",
    "    best_model.save(model_path_saved, save_format='tf')\n",
    "    print(f\"Model saved as SavedModel: {model_path_saved}\")\n",
    "    \n",
    "    # Convert to TensorFlow Lite for mobile deployment\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(best_model)\n",
    "    tflite_model = converter.convert()\n",
    "    \n",
    "    tflite_path = os.path.join(deployment_dir, f'{model_name}_model.tflite')\n",
    "    with open(tflite_path, 'wb') as f:\n",
    "        f.write(tflite_model)\n",
    "    print(f\"Model saved as TensorFlow Lite: {tflite_path}\")\n",
    "    \n",
    "    # Create model info file\n",
    "    model_info = {\n",
    "        'model_name': model_name,\n",
    "        'input_shape': list(IMG_SIZE) + [3],\n",
    "        'output_shape': [1],\n",
    "        'classes': CLASS_NAMES,\n",
    "        'preprocessing': {\n",
    "            'rescale': '1./255',\n",
    "            'resize': IMG_SIZE\n",
    "        },\n",
    "        'postprocessing': {\n",
    "            'threshold': 0.5,\n",
    "            'class_0': 'NORMAL',\n",
    "            'class_1': 'PNEUMONIA'\n",
    "        },\n",
    "        'performance': {\n",
    "            'accuracy': float(strong_results['accuracy'] if model_name == 'strong_augmentation' else baseline_results['accuracy']),\n",
    "            'precision': float(strong_results['precision'] if model_name == 'strong_augmentation' else baseline_results['precision']),\n",
    "            'recall': float(strong_results['recall'] if model_name == 'strong_augmentation' else baseline_results['recall']),\n",
    "            'f1_score': float(strong_results['f1'] if model_name == 'strong_augmentation' else baseline_results['f1'])\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    import json\n",
    "    with open(os.path.join(deployment_dir, f'{model_name}_info.json'), 'w') as f:\n",
    "        json.dump(model_info, f, indent=2)\n",
    "    \n",
    "    print(f\"Model info saved: {model_name}_info.json\")\n",
    "\n",
    "def create_inference_script():\n",
    "    \"\"\"Create a standalone inference script\"\"\"\n",
    "    \n",
    "    inference_code = '''\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import json\n",
    "import os\n",
    "\n",
    "class ChestXrayClassifier:\n",
    "    def __init__(self, model_path, model_info_path):\n",
    "        \"\"\"Initialize the classifier with model and info\"\"\"\n",
    "        self.model = tf.keras.models.load_model(model_path)\n",
    "        \n",
    "        with open(model_info_path, 'r') as f:\n",
    "            self.model_info = json.load(f)\n",
    "        \n",
    "        self.input_shape = tuple(self.model_info['input_shape'][:2])\n",
    "        self.classes = self.model_info['classes']\n",
    "        self.threshold = self.model_info['postprocessing']['threshold']\n",
    "    \n",
    "    def preprocess_image(self, image_path):\n",
    "        \"\"\"Preprocess image for prediction\"\"\"\n",
    "        # Load and resize image\n",
    "        img = Image.open(image_path).convert('RGB')\n",
    "        img = img.resize(self.input_shape)\n",
    "        \n",
    "        # Convert to array and normalize\n",
    "        img_array = np.array(img) / 255.0\n",
    "        img_array = np.expand_dims(img_array, axis=0)\n",
    "        \n",
    "        return img_array\n",
    "    \n",
    "    def predict(self, image_path):\n",
    "        \"\"\"Make prediction on a single image\"\"\"\n",
    "        # Preprocess\n",
    "        img_array = self.preprocess_image(image_path)\n",
    "        \n",
    "        # Predict\n",
    "        prediction = self.model.predict(img_array, verbose=0)[0][0]\n",
    "        \n",
    "        # Convert to class\n",
    "        predicted_class = int(prediction > self.threshold)\n",
    "        class_name = self.classes[predicted_class]\n",
    "        confidence = prediction if predicted_class == 1 else 1 - prediction\n",
    "        \n",
    "        return {\n",
    "            'class': class_name,\n",
    "            'confidence': float(confidence),\n",
    "            'raw_prediction': float(prediction),\n",
    "            'pneumonia_probability': float(prediction)\n",
    "        }\n",
    "    \n",
    "    def predict_batch(self, image_paths):\n",
    "        \"\"\"Make predictions on multiple images\"\"\"\n",
    "        results = []\n",
    "        for img_path in image_paths:\n",
    "            try:\n",
    "                result = self.predict(img_path)\n",
    "                result['image_path'] = img_path\n",
    "                results.append(result)\n",
    "            except Exception as e:\n",
    "                results.append({\n",
    "                    'image_path': img_path,\n",
    "                    'error': str(e)\n",
    "                })\n",
    "        return results\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize classifier\n",
    "    classifier = ChestXrayClassifier(\n",
    "        model_path=\"path/to/model.h5\",\n",
    "        model_info_path=\"path/to/model_info.json\"\n",
    "    )\n",
    "    \n",
    "    # Single prediction\n",
    "    result = classifier.predict(\"path/to/chest_xray.jpg\")\n",
    "    print(f\"Prediction: {result['class']} (confidence: {result['confidence']:.3f})\")\n",
    "    \n",
    "    # Batch prediction\n",
    "    image_paths = [\"image1.jpg\", \"image2.jpg\", \"image3.jpg\"]\n",
    "    results = classifier.predict_batch(image_paths)\n",
    "    \n",
    "    for result in results:\n",
    "        if 'error' not in result:\n",
    "            print(f\"{result['image_path']}: {result['class']} ({result['confidence']:.3f})\")\n",
    "        else:\n",
    "            print(f\"{result['image_path']}: Error - {result['error']}\")\n",
    "'''\n",
    "    \n",
    "    with open(os.path.join(RESULTS_DIR, 'deployment', 'inference.py'), 'w') as f:\n",
    "        f.write(inference_code)\n",
    "    \n",
    "    print(\"Inference script created: deployment/inference.py\")\n",
    "\n",
    "# Prepare both models for deployment\n",
    "print(\"Preparing models for deployment...\")\n",
    "\n",
    "# Determine which model to use as primary\n",
    "if strong_results['accuracy'] > baseline_results['accuracy']:\n",
    "    primary_model = model_strong_best\n",
    "    primary_name = \"strong_augmentation\"\n",
    "    print(\"Using Strong Augmentation Model as primary deployment model\")\n",
    "else:\n",
    "    primary_model = model_baseline_best\n",
    "    primary_name = \"baseline\"\n",
    "    print(\"Using Baseline Model as primary deployment model\")\n",
    "\n",
    "# Prepare primary model for deployment\n",
    "prepare_for_deployment(primary_model, primary_name)\n",
    "\n",
    "# Create inference script\n",
    "create_inference_script()\n",
    "\n",
    "print(\"\\nDeployment preparation completed!\")\n",
    "print(\"Files available in 'results/deployment/' directory:\")\n",
    "print(\"- Model weights (.h5, SavedModel, .tflite)\")\n",
    "print(\"- Model info (.json)\")\n",
    "print(\"- Inference script (.py)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea869c49",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def cleanup_and_summary():\n",
    "    \"\"\"Final cleanup and project summary\"\"\"\n",
    "    \n",
    "    print(\"🎉 CHEST X-RAY PNEUMONIA CLASSIFICATION PROJECT COMPLETED!\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # List all generated files\n",
    "    print(\"\\n📁 GENERATED FILES AND DIRECTORIES:\")\n",
    "    for root, dirs, files in os.walk(RESULTS_DIR):\n",
    "        level = root.replace(RESULTS_DIR, '').count(os.sep)\n",
    "        indent = ' ' * 2 * level\n",
    "        print(f\"{indent}{os.path.basename(root)}/\")\n",
    "        \n",
    "        sub_indent = ' ' * 2 * (level + 1)\n",
    "        for file in files:\n",
    "            size = os.path.getsize(os.path.join(root, file))\n",
    "            size_str = f\"({size/1024/1024:.1f}MB)\" if size > 1024*1024 else f\"({size/1024:.1f}KB)\"\n",
    "            print(f\"{sub_indent}{file} {size_str}\")\n",
    "    \n",
    "    print(f\"\\n🔍 QUICK ACCESS PATHS:\")\n",
    "    print(f\"├── Best Models: {RESULTS_DIR}/models/\")\n",
    "    print(f\"├── Training Plots: {RESULTS_DIR}/plots/\")\n",
    "    print(f\"├── Training Logs: {RESULTS_DIR}/*.csv\")\n",
    "    print(f\"├── Deployment Ready: {RESULTS_DIR}/deployment/\")\n",
    "    print(f\"└── Final Report: {RESULTS_DIR}/final_report.txt\")\n",
    "    \n",
    "    print(f\"\\n🎯 KEY TAKEAWAYS:\")\n",
    "    winner = \"Strong Augmentation\" if strong_results['accuracy'] > baseline_results['accuracy'] else \"Baseline\"\n",
    "    winner_acc = max(strong_results['accuracy'], baseline_results['accuracy'])\n",
    "    print(f\"✅ Best Model: {winner} Model ({winner_acc:.1%} accuracy)\")\n",
    "    print(f\"🔬 Architecture: Custom CNN with {complexity_stats['baseline_params']:,} parameters\")\n",
    "    print(f\"⚡ Inference Speed: ~{baseline_inference_time*1000:.0f}ms per image\")\n",
    "    print(f\"💾 Model Size: ~{complexity_stats['baseline_size_mb']:.1f}MB\")\n",
    "    \n",
    "    print(f\"\\n🚀 NEXT STEPS:\")\n",
    "    print(\"1. Review the final report for detailed analysis\")\n",
    "    print(\"2. Test the deployment-ready model with new images\")\n",
    "    print(\"3. Consider transfer learning with pre-trained models\")\n",
    "    print(\"4. Expand to multi-class classification (bacterial vs viral)\")\n",
    "    print(\"5. Implement grad-CAM for better interpretability\")\n",
    "    \n",
    "    print(f\"\\n📊 EXPERIMENT METRICS:\")\n",
    "    print(f\"{'Metric':<20} {'Baseline':<12} {'Strong Aug':<12} {'Winner'}\")\n",
    "    print(\"-\" * 50)\n",
    "    metrics = [\n",
    "        ('Accuracy', baseline_results['accuracy'], strong_results['accuracy']),\n",
    "        ('Precision', baseline_results['precision'], strong_results['precision']),\n",
    "        ('Recall', baseline_results['recall'], strong_results['recall']),\n",
    "        ('F1 Score', baseline_results['f1'], strong_results['f1']),\n",
    "        ('AUC', baseline_auc, strong_auc)\n",
    "    ]\n",
    "    \n",
    "    for metric, base_val, strong_val in metrics:\n",
    "        if base_val > strong_val:\n",
    "            winner_symbol = \"🏆 Baseline\"\n",
    "        elif strong_val > base_val:\n",
    "            winner_symbol = \"🏆 Strong\"\n",
    "        else:\n",
    "            winner_symbol = \"🤝 Tie\"\n",
    "        print(f\"{metric:<20} {base_val:<12.4f} {strong_val:<12.4f} {winner_symbol}\")\n",
    "    \n",
    "    print(f\"\\n💡 TIPS FOR IMPROVEMENT:\")\n",
    "    print(\"• Try transfer learning with ImageNet pre-trained models\")\n",
    "    print(\"• Experiment with different optimizers (SGD, AdamW)\")\n",
    "    print(\"• Implement cross-validation for more robust evaluation\")\n",
    "    print(\"• Add external validation with different hospital datasets\")\n",
    "    print(\"• Consider ensemble methods combining multiple models\")\n",
    "    \n",
    "    print(\"\\n✅ Project successfully completed! All results saved.\")\n",
    "\n",
    "# Run cleanup and show summary\n",
    "cleanup_and_summary()\n",
    "\n",
    "# Clear memory\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CHEST X-RAY PNEUMONIA CLASSIFICATION - END OF NOTEBOOK\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
